{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import Medline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_count(term):\n",
    "    \n",
    "    Entrez.email = \"carl.reynolds@imperial.ac.uk\"\n",
    "    count_handle = Entrez.esearch(db=\"pubmed\",\n",
    "                                  sort=\"relevance\",\n",
    "                                  retmode=\"xml\",\n",
    "                                  rettype=\"count\",\n",
    "                                  field=\"DP\",\n",
    "                                  term=term)\n",
    "    count_results = Entrez.read(count_handle)\n",
    "    count = int(count_results[\"Count\"])\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunked_pmids(term, chunksize=1000):\n",
    "    \n",
    "    count = get_count(term)\n",
    "    \n",
    "    retmax_requests = list(range(0, count, chunksize))\n",
    "                \n",
    "    pmids = []\n",
    "    \n",
    "    print(\"{} blocks to process\".format(len(retmax_requests)))\n",
    "    \n",
    "    for i, retmax in enumerate(retmax_requests):\n",
    "        \n",
    "        print(\"Processing block {}\".format(i))\n",
    "        \n",
    "        pmid_handle = Entrez.esearch(db=\"pubmed\",\n",
    "                                     sort=\"relevance\",\n",
    "                                     retmode=\"xml\",\n",
    "                                     usehistory='y',\n",
    "                                     retstart=retmax,\n",
    "                                     retmax=chunksize,\n",
    "                                     field=\"DP\",\n",
    "                                     term=term)\n",
    "        pmids.append(Entrez.read(pmid_handle)[\"IdList\"])\n",
    "        \n",
    "    return pmids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_medline(pmids):\n",
    "    \n",
    "    Entrez.email = \"carl.reynolds@imperial.ac.uk\"\n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           id=pmids,\n",
    "                           rettype='medline',\n",
    "                           retmode='text')\n",
    "    records = Medline.parse(handle)\n",
    "    \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_results_dict(pmid_chunks):\n",
    "    \"\"\"\n",
    "    Fetch_medline(chunk) returns a generator object of medline records. we iterate through it saving the records \n",
    "    to a list. We make a dict of the list indexed by the pubmed id. \n",
    "    \"\"\"\n",
    "    \n",
    "    temp_records = []\n",
    "    records = []\n",
    "    results = {}\n",
    "        \n",
    "    for chunk in tqdm(pmid_chunks):\n",
    "        temp_records = fetch_medline(chunk)\n",
    "        for record in temp_records:\n",
    "            records.append(record)\n",
    "    \n",
    "    for record in records:\n",
    "        results[record.get('PMID')] = record\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_a_year_of_medline(year):\n",
    "    \n",
    "    print(\"{} records to fetch\".format(get_count(year)))\n",
    "    pmid_chunks = chunked_pmids(year, 1000)\n",
    "    results = make_results_dict(pmid_chunks)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571781 records to fetch\n",
      "572 blocks to process\n",
      "Processing block 0\n",
      "Processing block 1\n",
      "Processing block 2\n",
      "Processing block 3\n",
      "Processing block 4\n",
      "Processing block 5\n",
      "Processing block 6\n",
      "Processing block 7\n",
      "Processing block 8\n",
      "Processing block 9\n",
      "Processing block 10\n",
      "Processing block 11\n",
      "Processing block 12\n",
      "Processing block 13\n",
      "Processing block 14\n",
      "Processing block 15\n",
      "Processing block 16\n",
      "Processing block 17\n",
      "Processing block 18\n",
      "Processing block 19\n",
      "Processing block 20\n",
      "Processing block 21\n",
      "Processing block 22\n",
      "Processing block 23\n"
     ]
    }
   ],
   "source": [
    "results = fetch_a_year_of_medline('2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
